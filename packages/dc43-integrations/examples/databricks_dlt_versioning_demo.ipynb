{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87876c7e",
   "metadata": {},
   "source": [
    "# Delta Live Tables governance batch demo\n",
    "\n",
    "Interactively explore how contract and dataset versions evolve when a Delta Live Tables pipeline publishes governed tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bd833e",
   "metadata": {},
   "source": [
    "## 1. Configure parameters\n",
    "\n",
    "Fill in the widgets (Databricks) or rely on environment variables when running locally. The notebook uses these values for Unity Catalog targets, dataset identifiers, and the optional local execution harness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a893746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def _resolve_param(name: str, *, default: str | None = None, label: str | None = None) -> str | None:\n",
    "    env_key = f\"DC43_DEMO_{name.upper()}\"\n",
    "    if 'dbutils' in globals():\n",
    "        try:\n",
    "            if label is None:\n",
    "                label = name\n",
    "            dbutils.widgets.text(name, os.environ.get(env_key, default) or '', label)\n",
    "            value = dbutils.widgets.get(name)\n",
    "            if value:\n",
    "                return value\n",
    "        except Exception as exc:  # pragma: no cover - widgets unavailable\n",
    "            print(f'Falling back to environment for {name}: {exc}')\n",
    "    return os.environ.get(env_key, default)\n",
    "\n",
    "\n",
    "CONFIG_PATH = _resolve_param('config_path', label='Service config (optional)')\n",
    "CATALOG = _resolve_param('catalog', default='main', label='Unity Catalog')\n",
    "SCHEMA = _resolve_param('schema', default='governed_demo', label='Schema')\n",
    "TABLE = _resolve_param('table', default='orders_dlt', label='DLT table name')\n",
    "DATASET_ID = _resolve_param('dataset_id', default='governed.analytics.orders')\n",
    "DATA_PRODUCT_ID = _resolve_param('data_product_id', default='dp.analytics.orders')\n",
    "OUTPUT_PORT = _resolve_param('output_port', default='orders')\n",
    "CONTRACT_ID = _resolve_param('contract_id', default='contracts.analytics.orders')\n",
    "DATASET_VERSION = _resolve_param('dataset_version', default='1.0.0', label='Dataset version')\n",
    "ENFORCE = (_resolve_param('enforce', default='false') or '').lower() in {'1', 'true', 'yes'}\n",
    "RUN_LOCAL = (_resolve_param('run_local', default='false', label='Execute locally?') or '').lower() in {'1', 'true', 'yes'}\n",
    "\n",
    "print('Configuration summary:')\n",
    "for key in ['CONFIG_PATH', 'CATALOG', 'SCHEMA', 'TABLE', 'DATASET_ID', 'DATA_PRODUCT_ID', 'OUTPUT_PORT', 'CONTRACT_ID', 'DATASET_VERSION', 'ENFORCE', 'RUN_LOCAL']:\n",
    "    print(f'  {key} = {globals()[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eea2ea",
   "metadata": {},
   "source": [
    "## 2. Initialise Spark and service clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "print(f'Using Spark {spark.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d329f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dc43_service_clients.bootstrap import load_service_clients\n",
    "\n",
    "\n",
    "suite = load_service_clients(CONFIG_PATH)\n",
    "if suite.contract is None or suite.data_product is None or suite.governance is None:\n",
    "    raise RuntimeError('Contract, data product, and governance services are required')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a3a771",
   "metadata": {},
   "source": [
    "## 3. Prepare Unity Catalog targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc461c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = f\"{CATALOG}.{SCHEMA}.{TABLE}\"\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SCHEMA}\")\n",
    "print(f'DLT pipeline writes governed data to {table_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff0370",
   "metadata": {},
   "source": [
    "## 4. Build contract revisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3216d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dc43_integrations.examples.databricks_delta_versioning_support import (\n",
    "    VersionedWriteSpec,\n",
    "    build_contract,\n",
    "    ensure_active_data_product,\n",
    "    register_contracts,\n",
    ")\n",
    "\n",
    "contracts = [\n",
    "    build_contract(\n",
    "        version='0.1.0',\n",
    "        contract_id=CONTRACT_ID,\n",
    "        table_name=table_name,\n",
    "        catalog=CATALOG,\n",
    "        schema=SCHEMA,\n",
    "        allowed_currencies=['EUR', 'USD'],\n",
    "        include_discount=False,\n",
    "    ),\n",
    "    build_contract(\n",
    "        version='0.2.0',\n",
    "        contract_id=CONTRACT_ID,\n",
    "        table_name=table_name,\n",
    "        catalog=CATALOG,\n",
    "        schema=SCHEMA,\n",
    "        allowed_currencies=['EUR', 'USD'],\n",
    "        include_discount=True,\n",
    "    ),\n",
    "    build_contract(\n",
    "        version='0.3.0',\n",
    "        contract_id=CONTRACT_ID,\n",
    "        table_name=table_name,\n",
    "        catalog=CATALOG,\n",
    "        schema=SCHEMA,\n",
    "        allowed_currencies=['EUR', 'USD', 'GBP'],\n",
    "        include_discount=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "register_contracts(suite.contract, contracts)\n",
    "for contract in contracts:\n",
    "    ensure_active_data_product(\n",
    "        data_product_service=suite.data_product,\n",
    "        data_product_id=DATA_PRODUCT_ID,\n",
    "        port_name=OUTPUT_PORT,\n",
    "        contract=contract,\n",
    "        physical_location=table_name,\n",
    "    )\n",
    "print(f'Registered {len(contracts)} contract revisions under {CONTRACT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddefe532",
   "metadata": {},
   "source": [
    "## 5. Select the dataset payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f97445",
   "metadata": {},
   "outputs": [],
   "source": [
    "writes = [\n",
    "    VersionedWriteSpec(\n",
    "        contract=contracts[0],\n",
    "        dataset_version='1.0.0',\n",
    "        rows=[\n",
    "            {\n",
    "                'order_id': 1,\n",
    "                'customer_id': 101,\n",
    "                'order_ts': '2024-01-01T10:00:00Z',\n",
    "                'amount': 125.5,\n",
    "                'currency': 'EUR',\n",
    "            },\n",
    "            {\n",
    "                'order_id': 2,\n",
    "                'customer_id': 102,\n",
    "                'order_ts': '2024-01-02T11:15:00Z',\n",
    "                'amount': 75.0,\n",
    "                'currency': 'USD',\n",
    "            },\n",
    "        ],\n",
    "    ),\n",
    "    VersionedWriteSpec(\n",
    "        contract=contracts[1],\n",
    "        dataset_version='1.1.0',\n",
    "        rows=[\n",
    "            {\n",
    "                'order_id': 1,\n",
    "                'customer_id': 101,\n",
    "                'order_ts': '2024-02-01T09:00:00Z',\n",
    "                'amount': 135.0,\n",
    "                'currency': 'EUR',\n",
    "                'discount_rate': 0.05,\n",
    "            },\n",
    "            {\n",
    "                'order_id': 2,\n",
    "                'customer_id': 102,\n",
    "                'order_ts': '2024-02-02T09:30:00Z',\n",
    "                'amount': 80.0,\n",
    "                'currency': 'USD',\n",
    "                'discount_rate': 0.10,\n",
    "            },\n",
    "        ],\n",
    "    ),\n",
    "    VersionedWriteSpec(\n",
    "        contract=contracts[2],\n",
    "        dataset_version='2.0.0',\n",
    "        rows=[\n",
    "            {\n",
    "                'order_id': 1,\n",
    "                'customer_id': 101,\n",
    "                'order_ts': '2024-03-01T08:30:00Z',\n",
    "                'amount': 140.0,\n",
    "                'currency': 'EUR',\n",
    "                'discount_rate': 0.08,\n",
    "            },\n",
    "            {\n",
    "                'order_id': 2,\n",
    "                'customer_id': 102,\n",
    "                'order_ts': '2024-03-02T12:45:00Z',\n",
    "                'amount': 82.5,\n",
    "                'currency': 'USD',\n",
    "                'discount_rate': 0.05,\n",
    "            },\n",
    "            {\n",
    "                'order_id': 3,\n",
    "                'customer_id': 103,\n",
    "                'order_ts': '2024-03-03T14:10:00Z',\n",
    "                'amount': 210.0,\n",
    "                'currency': 'GBP',\n",
    "                'discount_rate': 0.15,\n",
    "            },\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "\n",
    "SPEC_BY_VERSION = {spec.dataset_version: spec for spec in writes}\n",
    "AVAILABLE_VERSIONS = sorted(SPEC_BY_VERSION)\n",
    "active_spec = SPEC_BY_VERSION.get(DATASET_VERSION)\n",
    "if active_spec is None:\n",
    "    raise ValueError(f\"Unknown dataset version {DATASET_VERSION!r}; choose one of {AVAILABLE_VERSIONS}\")\n",
    "print(f\"Selected dataset version {active_spec.dataset_version} using contract {active_spec.contract.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc28e86",
   "metadata": {},
   "source": [
    "## 6. Define the governed DLT table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dc43_integrations.examples.databricks_delta_versioning_support import (\n",
    "    contract_has_discount,\n",
    "    make_dataframe,\n",
    ")\n",
    "from dc43_integrations.spark.dlt import governed_table\n",
    "from dc43_integrations.spark.dlt_local import ensure_dlt_module\n",
    "\n",
    "dlt = ensure_dlt_module(allow_stub=True)\n",
    "\n",
    "@governed_table(\n",
    "    dlt,\n",
    "    context={\n",
    "        'contract': {\n",
    "            'contract_id': active_spec.contract.id,\n",
    "            'contract_version': active_spec.contract.version,\n",
    "        },\n",
    "        'dataset_id': DATASET_ID,\n",
    "        'dataset_version': active_spec.dataset_version,\n",
    "        'output_binding': {\n",
    "            'data_product': DATA_PRODUCT_ID,\n",
    "            'port_name': OUTPUT_PORT,\n",
    "            'physical_location': table_name,\n",
    "        },\n",
    "    },\n",
    "    governance_service=suite.governance,\n",
    "    name=TABLE,\n",
    "    comment='Governed orders fact table (DLT batch demo)',\n",
    ")\n",
    "def orders():\n",
    "    return make_dataframe(\n",
    "        spark,\n",
    "        active_spec,\n",
    "        has_discount=contract_has_discount(active_spec.contract),\n",
    "    )\n",
    "\n",
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614f58d4",
   "metadata": {},
   "source": [
    "## 7. (Optional) Execute locally with the DLT harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ae26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_LOCAL:\n",
    "    from dc43_integrations.spark.dlt_local import LocalDLTHarness\n",
    "\n",
    "    with LocalDLTHarness(spark, module=dlt) as harness:\n",
    "        result = harness.run_asset(TABLE)\n",
    "        try:\n",
    "            if 'display' in globals():\n",
    "                display(result)\n",
    "            else:\n",
    "                result.show(truncate=False)\n",
    "        except Exception:\n",
    "            result.show(truncate=False)\n",
    "        if harness.expectation_reports:\n",
    "            print('Expectation summary:')\n",
    "            for report in harness.expectation_reports:\n",
    "                print(\n",
    "                    f\"- {report.asset}::{report.rule} [{report.action}] status={report.status} failures={report.failed_rows}\"\n",
    "                )\n",
    "else:\n",
    "    print('Set RUN_LOCAL to true to execute the asset with LocalDLTHarness outside a DLT pipeline.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8fd034",
   "metadata": {},
   "source": [
    "## 8. Inspect Delta table history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9cc5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dc43_integrations.examples.databricks_delta_versioning_support import describe_delta_history\n",
    "\n",
    "delta_history = describe_delta_history(spark, table_name)\n",
    "for record in delta_history:\n",
    "    version = record.get('version')\n",
    "    ts = record.get('timestamp')\n",
    "    op = record.get('operation')\n",
    "    print(f'version={version} timestamp={ts} operation={op}')\n",
    "delta_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f584d",
   "metadata": {},
   "source": [
    "## 9. Render the compatibility matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dc43_integrations.examples.databricks_delta_versioning_support import (\n",
    "    collect_status_matrix,\n",
    "    render_markdown_matrix,\n",
    ")\n",
    "\n",
    "entries = collect_status_matrix(suite.governance, dataset_id=DATASET_ID)\n",
    "markdown = render_markdown_matrix(entries)\n",
    "try:\n",
    "    if 'displayHTML' in globals():\n",
    "        displayHTML(f'<pre>{markdown}</pre>')\n",
    "    else:\n",
    "        print(markdown)\n",
    "except Exception:\n",
    "    print(markdown)\n",
    "markdown"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
