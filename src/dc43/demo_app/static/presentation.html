<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>dc43 pipeline presentation</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4/dist/reveal.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4/dist/theme/white.css">
</head>
<body>
<div class="reveal">
  <div class="slides">
    <section>
      <h1>dc43 Pipeline Demo</h1>
      <p>From contract to governed datasets</p>
    </section>

    <section>
      <h2>1. Define Data Contract</h2>
      <div style="display:flex; gap:2rem;">
        <pre style="flex:1"><code class="language-python">from open_data_contract_standard.model import OpenDataContractStandard
contract = OpenDataContractStandard(...)
</code></pre>
        <pre style="flex:1"><code class="language-json">{
  "fields": [
    {"name": "id", "type": "string"},
    {"name": "amount", "type": "double"}
  ],
  "expectations": ["amount > 0"]
}
</code></pre>
      </div>
      <p>Schema and quality rules capture structure and expectations.</p>
    </section>

    <section>
      <h2>2. Read with Contract</h2>
      <div style="display:flex; gap:2rem;">
        <pre style="flex:1"><code class="language-python">orders_df, status = read_with_contract(
    spark,
    path="orders.json",
    contract=orders_contract,
    dq_client=dq,
)
</code></pre>
        <pre style="flex:1"><code class="language-json">{
  "status": "success",
  "violations": []
}
</code></pre>
      </div>
      <p>Validates inputs and reports violations.</p>
    </section>

    <section>
      <h2>3. Transform with Spark</h2>
      <pre><code class="language-python">df = orders_df.join(customers_df, "customer_id")
</code></pre>
      <p>Use regular Spark APIs; contracts keep data clean.</p>
    </section>

    <section>
      <h2>4. Write with Contract</h2>
      <div style="display:flex; gap:2rem;">
        <pre style="flex:1"><code class="language-python">result, status, draft = write_with_contract(
    df,
    contract=output_contract,
    path=output_path,
    dq_client=dq,
    draft_on_mismatch=True,
)
</code></pre>
        <pre style="flex:1"><code class="language-json">{
  "metrics": {
    "row_count": 1000,
    "missing_customers": 5
  },
  "draft": "orders_v2"
}
</code></pre>
      </div>
      <p>Records metrics and drafts new contracts on mismatch.</p>
    </section>

    <section>
      <h2>5. Inspect Violations</h2>
      <div style="display:flex; gap:2rem;">
        <pre style="flex:1"><code class="language-python">status = attach_failed_expectations(
    df,
    output_contract,
    status,
    collect_examples=True,
)
</code></pre>
        <pre style="flex:1"><code class="language-json">[
  {
    "expectation": "amount > 0",
    "examples": ["amount=-3", "amount=0"]
  }
]
</code></pre>
      </div>
      <p>Examples help diagnose data quality issues.</p>
    </section>

    <section>
      <h2>6. Track Dataset Versions</h2>
      <div style="display:flex; gap:2rem;">
        <pre style="flex:1"><code class="language-python">records.append(DatasetRecord(...))
save_records(records)
</code></pre>
        <pre style="flex:1"><code class="language-json">[
  {
    "version": 1,
    "row_count": 1000,
    "status": "success"
  }
]
</code></pre>
      </div>
      <p>History shows evolution, metrics and status.</p>
    </section>

    <section>
      <h2>Manual Spark vs dc43</h2>
      <div style="display:flex; gap:2rem;">
        <div style="flex:1">
          <h3>Manual</h3>
          <pre><code class="language-python">df = spark.read.json("orders.json")
validate_schema(df)
compute_metrics(df)
df.write.save(output_path)
</code></pre>
        </div>
        <div style="flex:1">
          <h3>dc43</h3>
          <pre><code class="language-python">df, status = read_with_contract(spark, "orders.json", contract, dq)
result, status, draft = write_with_contract(df, contract, output_path, dq)
</code></pre>
        </div>
      </div>
      <p>dc43 removes boilerplate and centralizes quality rules.</p>
    </section>

    <section>
      <h2>Without vs With Contract</h2>
      <ul>
        <li><strong>Without:</strong> implicit schemas, ad-hoc checks, manual evolution</li>
        <li><strong>With:</strong> versioned contracts, documented expectations, automated drafts</li>
      </ul>
    </section>

    <section>
      <h2>Why dc43?</h2>
      <ul>
        <li>Fewer custom checks for data engineers and analysts</li>
        <li>Automatic metrics and draft contracts</li>
        <li>Traceable evolution for managers and governance</li>
        <li>Simple Spark code compared to vanilla</li>
      </ul>
    </section>
  </div>
</div>
<script src="https://cdn.jsdelivr.net/npm/reveal.js@4/dist/reveal.js"></script>
<script>
  Reveal.initialize();
</script>
</body>
</html>
